{{DISPLAYTITLE:ML_MCONF}}
{{TAGDEF|ML_MCONF|[integer]|see below}}

Description: This tag sets the maximum number of structures stored in memory that are used for training in the machine learning force field method.
----
The defaults for {{TAG|ML_MCONF}} are different for each different {{TAG|ML_MODE}} setting. Here are the defaults for each mode:
*{{TAG|ML_MODE}}='TRAIN':
**No {{TAG|ML_AB}} present (learning from scratch): min(1500, max(1,{{TAG|NSW}}))
**{{TAG|ML_AB}} present (continuation of learning): MCONF_AB + min(1500, max(1,{{TAG|NSW}}))
*{{TAG|ML_MODE}}='SELECT': MCONF_AB + 1
*{{TAG|ML_MODE}}='REFIT': MCONF_AB + 1
*{{TAG|ML_MODE}}='REFITBAYESIAN': MCONF_AB + 1
*{{TAG|ML_MODE}}='RUN': 1
using the following definition:
*MCONF_AB = Number of training structures read from the {{TAG|ML_AB}} file.


The default value for {{TAG|ML_MODE}}=''TRAIN'' is usually a safe value for solids and easy-to-learn liquids but should be set to a higher value as soon as it is reached. When this happens the code stops and gives an error instructing to increase {{TAG|ML_MCONF}}.

This flag sets also the maximum number of rows for the design matrix, which is usually a huge matrix. The design matrix is to be allocated statically at the beginning of the program since several parts of the code use MPI shared memory and dynamic reallocation of these arrays can cause severe problems on some systems. So most of the main arrays are statically allocated in the code.

An estimate of the design matrix and all other large arrays are printed out to the {{TAG|ML_LOGFILE}} before allocation. The design matrix is fully distributed in a block cyclic fashion for scaLAPACK and should almost perfectly linearly scale with the number of used processors.

== Related tags and articles ==

{{sc|ML_FF_MCONF|Examples|Examples that use this tag}}
----
{{TAG|ML_LMLFF}}, {{TAG|ML_MCONF_NEW}}, {{TAG|ML_MB}}

[[Category:INCAR tag]][[Category:Machine-learned force fields]][[Category:Memory]]
